# Magnetic Proxy - Ejemplo de Scraping Modular

Este proyecto demuestra cÃ³mo usar **Magnetic Proxy** para hacer scraping de productos de manera Ã©tica y legal, utilizando una arquitectura modular y reutilizable.

## ğŸ“ Estructura del Proyecto

```
magnetic-proxy/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py          # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ proxy/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ client.py             # Cliente reutilizable para el proxy
â”‚   â””â”€â”€ scraper/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ parser.py             # Funciones de parsing HTML
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ product_scraper.py        # Ejemplo completo de uso
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ—ï¸ Arquitectura Modular

### `src/config/settings.py`
MÃ³dulo de configuraciÃ³n centralizada que maneja:
- Credenciales del proxy (pueden venir de variables de entorno)
- URLs base para scraping
- Timeouts y delays configurables
- Constantes reutilizables

### `src/proxy/client.py`
Cliente del proxy que encapsula toda la lÃ³gica de conexiÃ³n:
- Clase `ProxyClient` con mÃ©todos `get()` y `post()`
- Manejo automÃ¡tico de delays entre requests
- Manejo de errores de conexiÃ³n
- Reutilizable para cualquier tipo de request HTTP

### `src/scraper/parser.py`
Funciones para parsear HTML y extraer datos:
- `parse_product()`: Extrae informaciÃ³n de un producto individual
- `parse_products_page()`: Parsea una pÃ¡gina completa de productos
- `get_next_page_url()`: Encuentra la URL de la siguiente pÃ¡gina
- FÃ¡cil de adaptar para otros sitios web

### `examples/product_scraper.py`
Script de ejemplo que demuestra:
- CÃ³mo configurar el proxy
- CÃ³mo usar el `ProxyClient` para hacer requests
- CÃ³mo parsear y extraer datos de productos
- Manejo de paginaciÃ³n
- Output de resultados

## ğŸš€ InstalaciÃ³n

### 1. Crear un entorno virtual (recomendado)

```bash
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

## âš™ï¸ ConfiguraciÃ³n

### OpciÃ³n 1: Archivo .env (MÃ¡s FÃ¡cil y Recomendado) â­

1. Crea un archivo `.env` en la raÃ­z del proyecto:

```bash
# Crear el archivo .env
touch .env
```

2. Agrega tus credenciales al archivo `.env`:

```env
MAGNETIC_PROXY_USER=carli.f.roman
MAGNETIC_PROXY_PASSWORD=tu_password_real_aqui
MAGNETIC_PROXY_HOST=rs.magneticproxy.net
MAGNETIC_PROXY_PORT=443
```

**Nota**: El formato del usuario puede variar. Usa exactamente el que te muestre el panel de Magnetic Proxy (puede ser solo `carli.f.roman` o el formato completo `customer-...`).

**âš ï¸ Importante**: Reemplaza `tu_password_real_aqui` con tu contraseÃ±a real del proxy.

3. El proyecto cargarÃ¡ automÃ¡ticamente las variables desde el archivo `.env` cuando ejecutes el script.

### OpciÃ³n 2: Variables de Entorno del Sistema

Configura las credenciales del proxy como variables de entorno:

```bash
export MAGNETIC_PROXY_USER="carli.f.roman"
export MAGNETIC_PROXY_PASSWORD="tu_password_real"
export MAGNETIC_PROXY_HOST="rs.magneticproxy.net"  # Opcional
export MAGNETIC_PROXY_PORT="443"                   # Opcional
```

### OpciÃ³n 3: ConfiguraciÃ³n Manual en el CÃ³digo

Puedes editar directamente `examples/product_scraper.py` y modificar las credenciales en la funciÃ³n `main()` (lÃ­neas 48-51).

## ğŸ“– Uso

### Ejecutar el ejemplo bÃ¡sico

**Pasos rÃ¡pidos:**

```bash
# 1. Activar el entorno virtual
source venv/bin/activate

# 2. Ejecutar el script
python3 examples/product_scraper.py
```

**O en una sola lÃ­nea:**

```bash
source venv/bin/activate && python3 examples/product_scraper.py
```

**QuÃ© hace el script:**
1. âœ… Se conecta al proxy usando tus credenciales del archivo `.env`
2. âœ… Hace scraping de productos desde `books.toscrape.com` (sitio diseÃ±ado para prÃ¡ctica)
3. âœ… Extrae: tÃ­tulo, precio, disponibilidad, rating
4. âœ… Muestra los resultados en consola
5. âœ… Maneja paginaciÃ³n automÃ¡ticamente

### Usar los mÃ³dulos en tu propio cÃ³digo

```python
from src.config.settings import ProxyConfig, ScraperConfig
from src.proxy.client import ProxyClient
from src.scraper.parser import parse_products_page

# Configurar proxy
proxy_config = ProxyConfig.from_env()  # O crear manualmente
client = ProxyClient(proxy_config, delay=1.0)

# Hacer request a travÃ©s del proxy
response = client.get("https://books.toscrape.com")

# Parsear productos
products = parse_products_page(response.text)

# Usar los datos
for product in products:
    print(f"{product['title']}: {product['price']}")
```

## ğŸ”§ PersonalizaciÃ³n

### Cambiar el sitio a scrapear

1. Modifica `ScraperConfig.base_url` en `examples/product_scraper.py`
2. Ajusta las funciones de parsing en `src/scraper/parser.py` segÃºn la estructura HTML del nuevo sitio

### Ajustar delays y timeouts

Modifica `ScraperConfig` en tu cÃ³digo:

```python
scraper_config = ScraperConfig(
    timeout=15,                    # Timeout mÃ¡s largo
    delay_between_requests=2.0     # MÃ¡s tiempo entre requests
)
```

### Usar el ProxyClient para otros tipos de requests

El `ProxyClient` no estÃ¡ limitado a scraping. Puedes usarlo para cualquier request HTTP:

```python
# GET request
response = client.get("https://api.example.com/data")

# POST request
response = client.post(
    "https://api.example.com/submit",
    json={"key": "value"}
)
```

## âš ï¸ Consideraciones Ã‰ticas

Este ejemplo estÃ¡ diseÃ±ado para ser Ã©tico y legal:

- âœ… Usa `books.toscrape.com`, un sitio diseÃ±ado especÃ­ficamente para prÃ¡ctica de scraping
- âœ… Incluye delays entre requests para no sobrecargar el servidor
- âœ… Respeta los lÃ­mites del sitio
- âœ… Solo extrae informaciÃ³n pÃºblica

**Importante**: Al usar este cÃ³digo con otros sitios, asegÃºrate de:
- Revisar y respetar `robots.txt`
- Verificar los tÃ©rminos de servicio del sitio
- Usar delays apropiados entre requests
- No hacer requests excesivos que puedan sobrecargar el servidor

## ğŸ› SoluciÃ³n de Problemas

### Error: "MAGNETIC_PROXY_USER y MAGNETIC_PROXY_PASSWORD deben estar configurados"

**SoluciÃ³n**: Configura las variables de entorno o edita las credenciales directamente en el cÃ³digo.

### Error: "Connection timeout"

**SoluciÃ³n**: 
- Verifica que las credenciales del proxy sean correctas
- Aumenta el timeout en `ScraperConfig`
- Verifica tu conexiÃ³n a internet

### Error: "ModuleNotFoundError"

**SoluciÃ³n**: AsegÃºrate de haber instalado las dependencias:
```bash
pip install -r requirements.txt
```

## ğŸ“ Dependencias

- `requests`: Para hacer HTTP requests a travÃ©s del proxy
- `beautifulsoup4`: Para parsear HTML
- `lxml`: Parser rÃ¡pido para BeautifulSoup
- `python-dotenv`: Para cargar variables de entorno desde archivo `.env`

## ğŸ¬ Demo en Video

Â¿Quieres ver cÃ³mo funciona? Revisa el video tutorial en TikTok donde explico paso a paso cÃ³mo usar este proyecto.

## ğŸ¤ Contribuir

Este es un proyecto de ejemplo. SiÃ©ntete libre de:
- Adaptar el cÃ³digo para tus necesidades
- Agregar nuevos parsers para otros sitios
- Mejorar el manejo de errores
- Agregar funcionalidades adicionales

## ğŸ“„ Licencia

Este proyecto es un ejemplo educativo. Ãšsalo responsablemente y respeta los tÃ©rminos de servicio de los sitios que visites.
